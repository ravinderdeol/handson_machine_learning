{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "import os\n",
    "import ssl\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the root url for downloading the data\n",
    "download_root = \"https://raw.githubusercontent.com/ageron/handson-ml2/master\"\n",
    "\n",
    "# set the path for saving the housing data\n",
    "housing_path = os.path.join(\"datasets\")\n",
    "\n",
    "# set the url for downloading the housing data\n",
    "housing_url = download_root + \"/datasets/housing/housing.tgz\"\n",
    "\n",
    "# function to fetch the housing data\n",
    "def fetch_housing_data(housing_url = housing_url, housing_path = housing_path):\n",
    "\n",
    "    # create the housing directory if it does not exist\n",
    "    os.makedirs(housing_path, exist_ok = True)\n",
    "\n",
    "    # set the path for saving the housing data\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "\n",
    "    # get the housing data from the url and save it\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "\n",
    "    # open the housing data\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "\n",
    "    # extract the housing data\n",
    "    housing_tgz.extractall(path = housing_path)\n",
    "\n",
    "    # close the housing data\n",
    "    housing_tgz.close()\n",
    "\n",
    "# disable ssl certificate verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# call the function to fetch the housing data\n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the housing data into a pandas dataframe\n",
    "def load_housing_data(housing_path = housing_path):\n",
    "\n",
    "    # set the path for loading the csv file for the housing data\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "\n",
    "    # read the csv file into a pandas dataframe and return it\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# call the function to load the housing data into the housing dataframe\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a summary of the housing dataframe\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the statistical summary of the numerical columns in the housing dataframe\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first few rows of the housing dataframe\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate historgrams of each column in the housing dataframe\n",
    "housing.hist(bins = 50, figsize = (20, 15))\n",
    "\n",
    "# display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset so that twenty percent is used for testing and set a random set for reproducibility\n",
    "train_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first few rows of the test set\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the housing dataframe which uses the cut function to categorizes the median incomes into categories\n",
    "# the bins parameter defines the ranges for each income category\n",
    "# the labels parameter assigns custom labels to each income category\n",
    "housing[\"income_category\"] = pd.cut(housing[\"median_income\"], bins = [0., 1.5, 3.0, 4.5, 6., np.inf], labels = [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispay the count of values in each income category\n",
    "housing[\"income_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a histogram of the income category column\n",
    "housing[\"income_category\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a stratified shuffle split object with one split and a test size of twenty percent with a random state of forty two for reproducibility\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# iterate over the splits and assign each dataset into stratified train and test sets based on the income category\n",
    "for train_index, test_index in split.split(housing, housing[\"income_category\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "# calculate the proportion of each income category in the stratified test set to understand the distribution of income categories in the test set\n",
    "strat_test_set[\"income_category\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of each income category in the entire housing dataset to understand the distribution of income categories\n",
    "housing[\"income_category\"].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the income category column from the stratified train and test sets before training a machine learning model\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_category\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the stratified train set to explore the data\n",
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a scatter plot of the long and lat columns with an alpha to visualize the density of the data points\n",
    "housing.plot(kind = \"scatter\", x = \"longitude\", y = \"latitude\", alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot to visualize the geographical distribution of housing data\n",
    "housing.plot(kind = \"scatter\", x = \"longitude\", y = \"latitude\", alpha = 0.4, s = housing[\"population\"] / 100, label = \"population\", figsize = (10, 7), c = \"median_house_value\", cmap = plt.get_cmap(\"jet\"), colorbar = True)\n",
    "\n",
    "# display the plot\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ratio of total rooms per household\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
    "\n",
    "# calculate the ratio of total bedrooms per room\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
    "\n",
    "# calculate the ratio of population per household\n",
    "housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation matrix to explore relationships between variables\n",
    "corr_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the correlation values of the median house value column in descending order\n",
    "# correlation coefficients close to one indicate strong positive correlation like the median house value tends to rise when median income rises\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a scatter plot to explore the relationship between the median house value and the median income\n",
    "housing.plot(kind = \"scatter\", x = \"median_income\", y = \"median_house_value\", alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for machine learning algorithms\n",
    "# separate features and labels to train an ml model on features variables and housing labels evaluating the performance of the model making predictions potentially on unseen data\n",
    "# creating a new dataframe that drops the target variable\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis = 1)\n",
    "\n",
    "# create a copy of the target variable as the labels\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in the dataset with the median value of the column\n",
    "# create an instance of the simple imputer class with the median strategy set\n",
    "imputer = SimpleImputer(strategy = \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that drops the text ocean proximity column\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the imputer to the housing numerical data\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the learned statistics from the imputer\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the median values of each column in the housing numerical data\n",
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the housing numerical dataframe using the imputer\n",
    "x = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe from the transformed data\n",
    "housing_tr = pd.DataFrame(x, columns = housing_num.columns, index = housing_num.index)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
